{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11bf82f7-aaf5-40dc-b10d-90f939a502fa",
   "metadata": {},
   "source": [
    "## Generating TorchScript"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96a07f8-aeec-47ab-afbc-0359c403b239",
   "metadata": {},
   "source": [
    "Source of code: https://discuss.pytorch.org/t/conversion-of-pytorch-pt-model-file-into-torchscript-ts-file/185671/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "54e5fd5f-5e87-4622-bff7-e6c3ce807350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import elephant_rumble_inference as eri\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2b15f496-f2c0-4960-a43a-13da1c8183c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "elephant_rumble_classifier = eri.ElephantRumbleClassifier().to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ec87b732-7f06-47db-85ec-2cb1c306d19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elephant_rumble_classifier.load_state_dict(torch.load(\"/Users/suhanashri/Downloads/Cornell ELP research/rumble_detector/elephant-rumble-inference/model_files/2024-07-03.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "53d11c7a-2089-4241-8617-cacbaaa4215f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElephantRumbleClassifier(\n",
       "  (act): LeakyReLU(negative_slope=0.01)\n",
       "  (linear1): Linear(in_features=768, out_features=192, bias=True)\n",
       "  (linear2): Linear(in_features=192, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elephant_rumble_classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a99f2b78-eed3-4bd0-b063-8b05b7997fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchscript_model = torch.jit.script(elephant_rumble_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "70af4640-0fc3-483b-9b0f-0a7939624f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.save(torchscript_model, 'torchscript_version.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7d6b4f5a-4798-4271-85b7-b255a21bec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if Torchscript file was created successfully\n",
    "ts_model = torch.jit.load('torchscript_version.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f98630-15cd-4866-85da-a7c462986007",
   "metadata": {},
   "source": [
    "## Performance Evaluation of Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfb8f24-e919-415c-99c1-9c92b883ce0a",
   "metadata": {},
   "source": [
    "Code taken from training_notebook.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030fe7d1-cf44-4149-b63b-cf3eeba18b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "aves_hubert_model = eri.AvesTorchaudioWrapper().to(DEVICE)\n",
    "raven_file_helper = eri.RavenFileHelper(\"/Users/suhanashri/Downloads/Cornell ELP research/testing dataset\")\n",
    "audio_file_processor = eri.AudioFileProcessor(aves_hubert_model,ts_model,device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e2f9f9-e822-4e76-9e40-7c34dcd4882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aves_embedding_cache_filename(audio_file,start,duration,preroll,postroll,sr):\n",
    "   prefix = f\"tmp/aves_embedding_cache/{sr}-{preroll}-{postroll}/{audio_file}\"\n",
    "   filename = f\"{prefix}/{start}-{duration}.pt\"\n",
    "   os.makedirs(prefix,exist_ok=True)\n",
    "   return filename\n",
    "\n",
    "def get_aves_embeddings_from_file_with_buffers(audio_file,start,duration,preroll,postroll,sr=AVES_SR):\n",
    "    cachefile = get_aves_embedding_cache_filename(audio_file,start,duration,preroll,postroll,sr)\n",
    "    if os.path.exists(cachefile):\n",
    "        return torch.load(cachefile,mmap=True)#.to('cpu').detach()\n",
    "    if preroll > start:\n",
    "        preroll = start\n",
    "    y = raven_file_helper.get_downsampled_tensor(audio_file,start-preroll,duration+preroll+postroll,new_sr=sr)\n",
    "    unit_vecs = get_normalized_aves_embeddings(y)#.to('cpu').detach()\n",
    "    preroll_index = int(audio_file_processor.time_to_score_index(preroll))\n",
    "    postroll_index = int(audio_file_processor.time_to_score_index(preroll+duration))\n",
    "    # .clone().detatch() to avoid saving the entire original vector\n",
    "    relevant_unit_vecs = unit_vecs[preroll_index:postroll_index].clone().detach()\n",
    "    torch.save(relevant_unit_vecs,cachefile)\n",
    "    return relevant_unit_vecs\n",
    "\n",
    "\n",
    "def get_interesting_embeddings(audio_file,labels,max_labels=9999,sr=AVES_SR):\n",
    "    interesting_embs = []\n",
    "    labels = labels[:max_labels]\n",
    "    with tqdm.tqdm(total=len(labels)) as pbar:\n",
    "        for idx,row in enumerate(labels):\n",
    "            unit_vecs = get_aves_embeddings_from_file_with_buffers(audio_file,row.bt,row.duration,500,200,sr)\n",
    "            if mean_embedding_per_label := False:\n",
    "                mean_tensor = einops.reduce(unit_vecs, 'h w -> w', 'mean')\n",
    "                mean_tensor = mean_tensor / mean_tensor.norm(p=2)\n",
    "                interesting_embs.append(mean_tensor.unsqueeze(0))\n",
    "            elif trim_labels := False:\n",
    "                # Idea - Trim training data bounding boxes that extend beyond the actual rumble\n",
    "                interesting_embs.append(unit_vecs[3:-3])\n",
    "            else:\n",
    "                interesting_embs.append(unit_vecs)\n",
    "            if idx >= max_labels:\n",
    "                break\n",
    "            #del(y,unit_vecs,mean_tensor)\n",
    "            pbar.update(1)\n",
    "        return torch.concat(interesting_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d350ffed-64b9-4cf8-b7fc-80ebfa423720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "\n",
    "def get_aves_embeddings(y):\n",
    "    with torch.inference_mode(): # torch.no_grad():\n",
    "      y32 = y.to(torch.float32).view(1,y.shape[0])\n",
    "      aves_embeddings = aves_hubert_model.forward(y32.to(DEVICE)).to('cpu').detach()\n",
    "      del(y32)\n",
    "      reshaped_tensor = einops.rearrange(aves_embeddings, '1 n d -> n d')  # remove that batch dimension\n",
    "      del(aves_embeddings)\n",
    "      if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "      return reshaped_tensor.to('cpu').detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e11a512-859c-4e84-b088-40d081c86ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_aves_embeddings(y):\n",
    "    with torch.inference_mode(): # torch.no_grad():\n",
    "      embs = get_aves_embeddings(y)\n",
    "      norms = embs.norm(p=2, dim=1, keepdim=True)\n",
    "      unit_vecs = embs / norms\n",
    "      return unit_vecs.to('cpu').detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf727cd-d858-4ab0-8bc9-fb86190c6213",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_for_labels_in_file(audio_file):\n",
    "    gc.collect()\n",
    "    labels = raven_file_helper.get_all_labels_for_wav_file(audio_file)\n",
    "    if len(labels) < 2:\n",
    "        return (None,None)\n",
    "    negative_labels = raven_file_helper.get_negative_labels(labels)\n",
    "    if len(negative_labels) < 2:\n",
    "        return (None,None)\n",
    "    print(f\"found {len(labels)} labels and {len(negative_labels)} negative labels in {audio_file}\")\n",
    "    interesting_embs = get_interesting_embeddings(audio_file,labels,9999,sr=AVES_SR)\n",
    "    uninteresting_embs = get_interesting_embeddings(audio_file,negative_labels,9999,sr=AVES_SR)\n",
    "    return interesting_embs, uninteresting_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ef5044-e5fe-44e4-9612-fcdc9644ee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "  def __init__(self, inputs, labels):\n",
    "    self.inputs = inputs\n",
    "    self.labels = torch.tensor([1 if l == 'rumble' else 0 for l in labels]) # convert labels to binary\n",
    "    self.len = self.labels.shape[0]\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.inputs[index].type(torch.float32), self.labels[index]\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.len\n",
    "  \n",
    "  def save(self,name):\n",
    "     torch.save((self.inputs,self.labels), f'mydataset_{name}.pt')\n",
    "\n",
    "  def load(self,name):\n",
    "    self.inputs,self.labels = torch.load(f'mydataset_{name}.pt')\n",
    "    self.len = self.labels.shape[0]\n",
    "  \n",
    "def make_dataset(interesting_files, balance_classes=True):\n",
    "  iea=[]\n",
    "  uea=[]\n",
    "  for f in interesting_files:\n",
    "      ie,ue = get_embeddings_for_labels_in_file(f)\n",
    "      if ie is not None and ue is not None:\n",
    "          iea.append(ie)\n",
    "          uea.append(ue)\n",
    "  interesting_embs= torch.cat(iea)\n",
    "  uninteresting_embs = torch.cat(uea)\n",
    "  del(iea)\n",
    "  del(uea)\n",
    "  gc.collect()\n",
    "  if balance_classes:\n",
    "      # should probably be true - it worked really well with it true\n",
    "      print(\"initially, the shapes were\",interesting_embs.shape,uninteresting_embs.shape)\n",
    "      print(\"or a ratio of\",uninteresting_embs.shape[0] / interesting_embs.shape[0])\n",
    "      num_rows_to_keep = interesting_embs.shape[0]\n",
    "      random_indices = torch.randperm(uninteresting_embs.shape[0])[:num_rows_to_keep]\n",
    "      uninteresting_embs = uninteresting_embs[random_indices]\n",
    "  print(f\"from {len(interesting_files)} found {interesting_embs.shape} positive and {uninteresting_embs.shape} negatives\")\n",
    "  all_embs = torch.cat((interesting_embs, uninteresting_embs), dim=0)\n",
    "  all_labels = np.concatenate((np.array(['rumble'] * interesting_embs.shape[0]), \n",
    "                                np.array(['not'] * uninteresting_embs.shape[0])))\n",
    "  return MyDataset(all_embs, all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9161d970-8468-4ccc-b4be-b04adfc55539",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_files = [\"twenty_four_hr_file.wav\"]\n",
    "testing_dataset = make_dataset(testing_files, balance_classes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5686d555-ecdf-4c77-9437-ccec2a2fde0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_loader = DataLoader(testing_dataset, batch_size=1000, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b696937-eb62-4851-8e19-f48f4c5c16b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            \n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_outputs.extend(outputs.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_predictions), np.array(all_labels), np.array(all_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103ec77a-3421-43fe-8771-60bddb2f9304",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_pred,ts_true,ts_scores = get_predictions(ts_model, testing_loader, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cdda2f-f309-4b82-b477-84c2379ca6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['not rumbles','rumbles']\n",
    "print(classification_report(ts_true, ts_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e288473d-ac47-49e5-9452-f408779454c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
